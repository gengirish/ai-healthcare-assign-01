{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# Deep Learning for OCT Image Classification using MedMNIST Dataset\n",
        "\n",
        "**IIIT Dharwad - AI in Healthcare Case Study Assignment 1**\n",
        "\n",
        "This notebook implements CNN models for classifying OCT images from the OCTMNIST dataset into multiple retinal disease categories with explainability using Grad-CAM.\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Project Overview\n",
        "\n",
        "- **Objective**: Classify OCT images into 4 retinal disease categories\n",
        "- **Dataset**: OCTMNIST from MedMNIST collection\n",
        "- **Models**: Custom CNN vs Pretrained ResNet50\n",
        "- **Evaluation**: Comprehensive metrics + Grad-CAM explainability\n",
        "- **Classes**: CNV, DME, Drusen, Normal\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## üîß Environment Setup and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_dependencies"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install medmnist\n",
        "!pip install opencv-python\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.applications import ResNet50, VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "import cv2\n",
        "from itertools import cycle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"‚úÖ All dependencies installed and imported successfully!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_loading"
      },
      "source": [
        "## üìä Data Loading and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [],
      "source": [
        "# Initialize dataset\n",
        "data_flag = 'octmnist'\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "print(f\"Dataset: {data_flag}\")\n",
        "print(f\"Task: {task}\")\n",
        "print(f\"Number of channels: {n_channels}\")\n",
        "print(f\"Number of classes: {n_classes}\")\n",
        "print(f\"Class labels: {info['label']}\")\n",
        "\n",
        "# Load datasets\n",
        "print(\"\\nLoading OCTMNIST dataset...\")\n",
        "train_dataset = DataClass(split='train', download=True)\n",
        "val_dataset = DataClass(split='val', download=True)\n",
        "test_dataset = DataClass(split='test', download=True)\n",
        "\n",
        "# Extract data and labels\n",
        "x_train, y_train = train_dataset.imgs, train_dataset.labels\n",
        "x_val, y_val = val_dataset.imgs, val_dataset.labels\n",
        "x_test, y_test = test_dataset.imgs, test_dataset.labels\n",
        "\n",
        "print(f\"Training set shape: {x_train.shape}\")\n",
        "print(f\"Validation set shape: {x_val.shape}\")\n",
        "print(f\"Test set shape: {x_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "visualize_data"
      },
      "outputs": [],
      "source": [
        "# Visualize class distribution\n",
        "train_labels = train_dataset.labels.flatten()\n",
        "unique, counts = np.unique(train_labels, return_counts=True)\n",
        "class_distribution = dict(zip(unique, counts))\n",
        "\n",
        "print(\"Class Distribution in Training Set:\")\n",
        "for class_idx, count in class_distribution.items():\n",
        "    class_name = info['label'][str(class_idx)]\n",
        "    print(f\"Class {class_idx} ({class_name}): {count} samples\")\n",
        "\n",
        "# Plot class distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "class_names = [info['label'][str(i)] for i in unique]\n",
        "colors = ['skyblue', 'lightcoral', 'lightgreen', 'gold']\n",
        "bars = plt.bar(class_names, counts, color=colors)\n",
        "plt.title('Class Distribution in OCTMNIST Training Set', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Disease Categories')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, count in zip(bars, counts):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 500, \n",
        "             str(count), ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Check for class imbalance\n",
        "max_count = max(counts)\n",
        "min_count = min(counts)\n",
        "imbalance_ratio = max_count / min_count\n",
        "print(f\"\\nClass Imbalance Analysis:\")\n",
        "print(f\"Imbalance ratio: {imbalance_ratio:.2f}\")\n",
        "class_imbalance = imbalance_ratio > 2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sample_images"
      },
      "outputs": [],
      "source": [
        "# Visualize sample images\n",
        "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in range(16):\n",
        "    img = train_dataset.imgs[i]\n",
        "    label = train_dataset.labels[i].item()\n",
        "    class_name = info['label'][str(label)]\n",
        "    \n",
        "    axes[i].imshow(img.squeeze(), cmap='gray')\n",
        "    axes[i].set_title(f'Class {label}: {class_name}', fontsize=10)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Sample OCT Images from Each Class', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preprocessing"
      },
      "source": [
        "## üîÑ Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preprocess_data"
      },
      "outputs": [],
      "source": [
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_val = x_val.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train_cat = keras.utils.to_categorical(y_train, n_classes)\n",
        "y_val_cat = keras.utils.to_categorical(y_val, n_classes)\n",
        "y_test_cat = keras.utils.to_categorical(y_test, n_classes)\n",
        "\n",
        "print(f\"Preprocessed training data shape: {x_train.shape}\")\n",
        "print(f\"Preprocessed training labels shape: {y_train_cat.shape}\")\n",
        "print(\"‚úÖ Data preprocessing completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_creation"
      },
      "source": [
        "## üèóÔ∏è Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "custom_cnn"
      },
      "outputs": [],
      "source": [
        "# Create Custom CNN Model\n",
        "def create_custom_cnn():\n",
        "    model = models.Sequential([\n",
        "        # First Convolutional Block\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        \n",
        "        # Second Convolutional Block\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        \n",
        "        # Third Convolutional Block\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dropout(0.5),\n",
        "        \n",
        "        # Dense layers\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        \n",
        "        # Output layer\n",
        "        layers.Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Create Pretrained ResNet50 Model\n",
        "def create_resnet50_model():\n",
        "    # Input layer\n",
        "    input_tensor = layers.Input(shape=(28, 28, 1))\n",
        "    # Convert grayscale to RGB\n",
        "    x = layers.Conv2D(3, (1, 1), activation='linear')(input_tensor)\n",
        "    \n",
        "    # Load pretrained ResNet50\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=x)\n",
        "    base_model.trainable = False  # Freeze base model\n",
        "    \n",
        "    # Add custom classification head\n",
        "    x = base_model.output\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    predictions = layers.Dense(n_classes, activation='softmax')(x)\n",
        "    \n",
        "    model = models.Model(inputs=input_tensor, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "# Create models\n",
        "print(\"Creating Custom CNN Model...\")\n",
        "custom_model = create_custom_cnn()\n",
        "print(\"‚úÖ Custom CNN created!\")\n",
        "\n",
        "print(\"\\nCreating ResNet50 Model...\")\n",
        "resnet_model = create_resnet50_model()\n",
        "print(\"‚úÖ ResNet50 created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "compile_models"
      },
      "outputs": [],
      "source": [
        "# Compile models\n",
        "custom_model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "resnet_model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Models compiled successfully!\")\n",
        "\n",
        "# Display model summaries\n",
        "print(\"\\nCustom CNN Summary:\")\n",
        "custom_model.summary()\n",
        "\n",
        "print(f\"\\nCustom CNN Parameters: {custom_model.count_params():,}\")\n",
        "print(f\"ResNet50 Parameters: {resnet_model.count_params():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training"
      },
      "source": [
        "## üéØ Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_custom"
      },
      "outputs": [],
      "source": [
        "# Calculate class weights if needed\n",
        "class_weights = None\n",
        "if class_imbalance:\n",
        "    classes = np.unique(train_labels)\n",
        "    weights = compute_class_weight('balanced', classes=classes, y=train_labels)\n",
        "    class_weights = dict(zip(classes, weights))\n",
        "    print(\"Class weights:\", class_weights)\n",
        "\n",
        "# Define callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-7, verbose=1)\n",
        "]\n",
        "\n",
        "# Train Custom CNN\n",
        "print(\"Training Custom CNN...\")\n",
        "history1 = custom_model.fit(\n",
        "    x_train, y_train_cat,\n",
        "    batch_size=32,\n",
        "    epochs=15,\n",
        "    validation_data=(x_val, y_val_cat),\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Custom CNN training completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_resnet"
      },
      "outputs": [],
      "source": [
        "# Train ResNet50\n",
        "print(\"Training ResNet50...\")\n",
        "history2 = resnet_model.fit(\n",
        "    x_train, y_train_cat,\n",
        "    batch_size=32,\n",
        "    epochs=15,\n",
        "    validation_data=(x_val, y_val_cat),\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ ResNet50 training completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plot_history"
      },
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "def plot_training_history(history, model_name):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    # Plot accuracy\n",
        "    ax1.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
        "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
        "    ax1.set_title(f'{model_name} - Model Accuracy', fontsize=14, fontweight='bold')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot loss\n",
        "    ax2.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
        "    ax2.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "    ax2.set_title(f'{model_name} - Model Loss', fontsize=14, fontweight='bold')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot histories\n",
        "plot_training_history(history1, \"Custom CNN\")\n",
        "plot_training_history(history2, \"ResNet50\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaluation"
      },
      "source": [
        "## üìà Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluate_models"
      },
      "outputs": [],
      "source": [
        "# Evaluation function\n",
        "def evaluate_model(model, model_name):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"EVALUATING {model_name.upper()}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    # Make predictions\n",
        "    y_pred_proba = model.predict(x_test)\n",
        "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "    y_true = np.argmax(y_test_cat, axis=1)\n",
        "    \n",
        "    # Basic metrics\n",
        "    test_loss, test_accuracy = model.evaluate(x_test, y_test_cat, verbose=0)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    \n",
        "    # Classification report\n",
        "    class_names = [info['label'][str(i)] for i in range(n_classes)]\n",
        "    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
        "    \n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "    \n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "               xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f'{model_name} - Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # ROC Curves\n",
        "    y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
        "    \n",
        "    plt.figure(figsize=(10, 8))\n",
        "    colors = ['aqua', 'darkorange', 'cornflowerblue', 'red']\n",
        "    \n",
        "    for i, color in zip(range(n_classes), colors):\n",
        "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_proba[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, color=color, lw=2,\n",
        "                label=f'{class_names[i]} (AUC = {roc_auc:.3f})')\n",
        "    \n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'{model_name} - ROC Curves', fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'Test Accuracy': test_accuracy,\n",
        "        'Test Loss': test_loss,\n",
        "        'Macro Avg Precision': report['macro avg']['precision'],\n",
        "        'Macro Avg Recall': report['macro avg']['recall'],\n",
        "        'Macro Avg F1-Score': report['macro avg']['f1-score']\n",
        "    }\n",
        "\n",
        "# Evaluate both models\n",
        "metrics1 = evaluate_model(custom_model, \"Custom CNN\")\n",
        "metrics2 = evaluate_model(resnet_model, \"ResNet50\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "compare_models"
      },
      "outputs": [],
      "source": [
        "# Model Comparison\n",
        "comparison_df = pd.DataFrame([metrics1, metrics2])\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Visualize comparison\n",
        "metrics_to_plot = ['Test Accuracy', 'Macro Avg Precision', 'Macro Avg Recall', 'Macro Avg F1-Score']\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, metric in enumerate(metrics_to_plot):\n",
        "    values = [metrics1[metric], metrics2[metric]]\n",
        "    models = [metrics1['Model'], metrics2['Model']]\n",
        "    \n",
        "    bars = axes[i].bar(models, values, color=['skyblue', 'lightcoral'])\n",
        "    axes[i].set_title(f'{metric} Comparison', fontweight='bold')\n",
        "    axes[i].set_ylabel(metric)\n",
        "    axes[i].set_ylim(0, 1)\n",
        "    \n",
        "    # Add value labels\n",
        "    for bar, value in zip(bars, values):\n",
        "        axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                    f'{value:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Determine better model\n",
        "better_model = \"Custom CNN\" if metrics1['Test Accuracy'] > metrics2['Test Accuracy'] else \"ResNet50\"\n",
        "print(f\"\\nüèÜ Better performing model: {better_model}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gradcam"
      },
      "source": [
        "## üî¨ Grad-CAM Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gradcam_implementation"
      },
      "outputs": [],
      "source": [
        "# Grad-CAM Implementation\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    # Create gradient model\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    \n",
        "    # Compute gradients\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "    \n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    \n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
